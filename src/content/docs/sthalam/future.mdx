---
title: "Future Concepts"
description: "Exploratory ideas for enhancing Sthalam with interactive applications and discoverability"
---

> **Exploratory Concepts**: The following describes potential future directions for Sthalam. None of this is currently implemented or planned in detail. These represent aspirational thinking about possibilities.

## Interactive Applications with JEXL

**JEXL (JavaScript Expression Language)** could enable sovereign individuals to build interactive applications with custom logic—without writing code or relying on platforms.

Publishers could define business rules using simple expressions:

```jexl
total = (quantity * price) * (1 - discount) + shipping + tax
showShipping = productType == "physical"
eligible = age >= 18 && hasConsent
```

This would open up **more interactive sovereign applications** beyond static publishing:

- E-commerce stores with custom pricing and checkout logic
- Restaurant ordering with menu customization
- Service marketplaces with availability management
- Booking systems with flexible policies

All customizable to each sovereign individual's unique business rules—without platform constraints.

## Human-Readable Names via Blockchain

Currently, sharing content requires base64-encoded connection strings (large text blobs). Blockchain could enable **human-readable names** similar to ENS or DNS.

**The Vision**: Register names like `@alice` or `myblog.sthalam` that resolve to connection strings, enabling:

- Simple sharing (type a name instead of pasting a blob)
- Content discovery (browse and search for publishers)
- Multi-device updates (change nodes without resharing)

Blockchain would be optional—direct connection string sharing would still work. It would simply add a naming and discovery layer on top.

## Interactive Bidirectional Workflows

The current model uses append-only submissions to publisher-owned documents. An interesting direction would be **viewer-owned submission documents** where:

- Viewers create and own their submissions
- Publishers receive delegated access to read and update
- Updates flow bidirectionally
- Viewers can delete their data anytime

This could enable sovereign alternatives to centralized platforms:

- **E-commerce**: Viewers place orders they own, publishers update status, viewers can cancel
- **Restaurant ordering**: Viewers control orders, restaurants update status (preparing → ready)
- **Service marketplaces**: Viewers create requests, providers respond, back-and-forth negotiation
- **Booking systems**: Viewers own bookings, providers manage availability

All without platform intermediaries or transaction fees.

## Sovereign LLM Template Generation

Currently, users generate HUML templates using external LLMs (ChatGPT, Claude) by uploading template guides. The vision is to bring **LLM capabilities directly into the sovereign node** infrastructure:

**Node-Hosted LLMs**: Run language models on your sovereign node hardware with AI acceleration
- **Hardware Options**: Boards like Radxa Orion 6 with built-in NPUs for AI inference
- **Local Processing**: Template generation happens on your own infrastructure
- **No External Dependencies**: No need for ChatGPT, Claude, or other third-party AI services
- **Privacy by Design**: Design conversations never leave your sovereign node

**Conversational Template Generation**:
- **Natural Language Design**: Describe websites in conversation—LLM generates HUML code in real-time
- **CRDT-Aware**: LLM understands the template engine and CRDT synchronization architecture
- **Iterative Refinement**: "Add a contact form," "change the layout," "make it responsive"
- **Context Preservation**: LLM reads through existing templates and maintains conversation context
- **Real-Time Preview**: Generate and preview templates as you describe them

**Why Node-Hosted Matters**:
- **True Sovereignty**: AI capabilities run on hardware you control physically
- **Privacy Preservation**: Content creation conversations stay within your infrastructure
- **Offline Capability**: Generate templates without internet connectivity
- **Cost Control**: No API fees or usage limits
- **Learning**: LLM can learn from your templates to match your style

The combination of CRDTs for synchronization, peer-to-peer architecture for distribution, and **node-hosted LLMs for generation** would make Sthalam the first platform where content creation, design, and publishing all happen on sovereign infrastructure—without any platform dependencies.

## Why These Matter

These concepts would transform Sthalam from a publishing platform into **infrastructure for sovereign applications**—enabling individuals to run interactive businesses on their own terms, with their own logic, without centralized platforms.
